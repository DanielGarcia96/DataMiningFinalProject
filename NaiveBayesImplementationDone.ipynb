{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Adult Dataset\n",
      "Accuracy from implementation: 82.3039832928964%\n",
      "\n",
      "For BUPA Dataset\n",
      "Accuracy from implementation: 51.30434782608696%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Abbreviations:\n",
    "# DS: data set\n",
    "# df: data frame\n",
    "import csv, random, math\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Map string attributes to integer values\n",
    "def map_stringAttributes(df, attr_hash, class_column):\n",
    "    df_new = df.copy()\n",
    "    classes = df_new[class_column].unique()\n",
    "    for i in range (len(df.columns)):\n",
    "        attr_name = df.columns[i]                      # attribute name\n",
    "        value = df.iloc[0][attr_name]                  # first value in column\n",
    "        if (isinstance(value, str) == True):           # check if value is a string\n",
    "            attr_values = df_new[attr_name].unique()   # unique values for attribute\n",
    "            # map integers for each unique attribute value\n",
    "            map_to_int = {name: n for n, name in enumerate(attr_values)}\n",
    "            # replace data in dataset with its respective int\n",
    "            df_new[attr_name] = df_new[attr_name].replace(map_to_int)\n",
    "            # store list of attribute values and their int mapping to attribute name\n",
    "            attr_hash[attr_name] = list(enumerate(attr_values))\n",
    "    return (df_new, attr_hash, classes)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "def splitDataset(df, splitRatio):\n",
    "    trainingSize = int(len(df.index) * splitRatio)\n",
    "    trainingSet = []\n",
    "    testingSet = list(df.index)  # shallow copy of dataframe\n",
    "    while len(trainingSet) < trainingSize:\n",
    "        # get a random row from testingSet\n",
    "        index = random.randint(1, len(testingSet))-1\n",
    "        # remove index row from copy and\n",
    "        # add it to training set\n",
    "        trainingSet.append(testingSet.pop(index))\n",
    "    return (trainingSet, testingSet)\n",
    "\n",
    "# Separate dataset by their class labels\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range (len(dataset)):\n",
    "        row = dataset[i]\n",
    "       # print(\"row:\", df.iloc[row])\n",
    "        # check if class label is in dictionary\n",
    "        if (row[-1] not in separated):\n",
    "            # empty entry for class label\n",
    "            separated[row[-1]] = []\n",
    "        # add row to its class label dataset\n",
    "        separated[row[-1]].append(row)\n",
    "    return separated\n",
    "\n",
    "# Return mean of values\n",
    "def mean(values):\n",
    "    return sum(values)/float(len(values))\n",
    "\n",
    "# Return standard deviation of values\n",
    "def std_dev(values):\n",
    "    avg = mean(values)\n",
    "    variance = 0\n",
    "    # calculate variance\n",
    "    for i in range (0, len(values), 1):\n",
    "        variance = values[i]**2\n",
    "    variance = ( (variance/float((len(values)-1))) - (avg**2) )\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "# Summarize dataset by calculating mean and\n",
    "# standard deviation for each attribute\n",
    "def summarize(df):\n",
    "    import numpy as np\n",
    "    summaries = [(np.mean(column), np.std(column)) for column in zip(*df)]\n",
    "    #delete class label from summaries\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "# Summarize dataset by class labels\n",
    "def summarizeByClass(df):\n",
    "    separated = separateByClass(df)\n",
    "    summaries = {}\n",
    "    # separate summaries by class labels\n",
    "    for classLabel, instance in separated.items():\n",
    "        summaries[classLabel] = summarize(instance)\n",
    "    return summaries\n",
    "\n",
    "def convertStr(listX):\n",
    "    for i in range(len(listX)):\n",
    "        listX[i] = [float(x) for x in listX[i]]\n",
    "    return listX\n",
    "\n",
    "#calculate guassian probalbility\n",
    "def calculate_guassian(value, mean , std):\n",
    "    import math\n",
    "    exp = math.exp(-(math.pow(value-mean,2)/(2*math.pow(std,2))))\n",
    "    return (1/(math.sqrt(2*math.pi)* std)) * exp\n",
    "\n",
    "# a dictionary of summaries  is passed,along with a list values\n",
    "#for every class_summaries \n",
    "#make sure that probability is initialized with one to avoid probalilities of zero\n",
    "#for every  value class summary \n",
    "#get the mean and std of their repective column \n",
    "#get their value for that column \n",
    "#calculate the guassian probability and iteratively multiply for each column for a tuple.\n",
    "def class_probability(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue , classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, std = classSummaries[i]\n",
    "            value = inputVector[i]\n",
    "            probabilities[classValue] *= calculate_guassian(value,mean, std)\n",
    "    return probabilities\n",
    "\n",
    "#find class probabilities given class summaries and input vector\n",
    "#find the class probability for each tuple\n",
    "#pick the maxi-probability class for that tuple\n",
    "def predict_class(summaries, inputVectors):\n",
    "    probabilities = class_probability(summaries,inputVectors)\n",
    "    bestLabel, bestProb = None, -1;\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "#Transform the data back to it normal form after splitD\n",
    "def Transform(index, data):\n",
    "    superList = []\n",
    "    for i in range(0, len(data), 1):\n",
    "        superList.append(list(data.iloc[i]))\n",
    "    return superList\n",
    "#get the class values predicted for\n",
    "def getClass(class_summ, testSet):\n",
    "    predictions = []\n",
    "    for i in range(0,len(testSet), 1):\n",
    "        predictX = predict_class(class_summ, testSet[i])\n",
    "        predictions.append(predictX)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def MakeUnseen(dataset):\n",
    "    for i in range(0, len(dataset), 1):\n",
    "        dataset[i][-1] = '?'\n",
    "    return dataset   \n",
    "\n",
    "# Data frames for their respective data set\n",
    "adult_df = pd.read_csv(\"Adult_DS.csv\")\n",
    "bupa_df = pd.read_csv(\"bupa_DS.csv\")\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "# Create list of attribtues for each DS\n",
    "adult_attributes = list(adult_df.columns[:14])\n",
    "bupa_attributes = list(bupa_df.columns[:6])\n",
    "\n",
    "adult_mapping = {}        # hash table for adult attributes\n",
    "adult_df2, adult_mapping, adult_classes = map_stringAttributes(adult_df, adult_mapping, \"annual-income\")\n",
    "bupa_classes = list(bupa_df[\"selector\"].unique())    \n",
    "\n",
    "# Test\n",
    "splitRatio = 0.67\n",
    "adult_trainingSet, adult_testingSet = splitDataset(adult_df2, splitRatio)\n",
    "bupa_trainingSet, bupa_testingSet = splitDataset(bupa_df, splitRatio)\n",
    "\n",
    "# training set data\n",
    "adult_training = Transform(adult_trainingSet,adult_df2)\n",
    "bupa_training = Transform(bupa_trainingSet, bupa_df)\n",
    "\n",
    "#testing set data \n",
    "adult_testingWC = Transform(adult_testingSet,adult_df2)\n",
    "bupa_testingWC = Transform(bupa_testingSet, bupa_df)\n",
    "\n",
    "#testing set data >>>> this hold the data,to avoid variable name conflict \n",
    "adult_trans2 = Transform(adult_testingSet,adult_df2)\n",
    "bupa_trans2 = Transform(bupa_testingSet, bupa_df)\n",
    "\n",
    "#tesing set without a class label ; can print them to see what they are.\n",
    "adult_testingNC = MakeUnseen(adult_trans2)\n",
    "bupa_testingNC = MakeUnseen(bupa_trans2)\n",
    "\n",
    "# Get class summaries for each class label\n",
    "adult_class_sum = summarizeByClass(adult_training)\n",
    "bupa_class_sum = summarizeByClass(bupa_training)\n",
    "\n",
    "# Compute accuracies for datasets\n",
    "adult_r = getClass(adult_class_sum, adult_testingNC)\n",
    "adult_accuracy =  getAccuracy(adult_testingWC, adult_r)\n",
    "bupa_r = getClass(bupa_class_sum, bupa_testingNC)\n",
    "bupa_accuracy = getAccuracy(bupa_testingWC, bupa_r)\n",
    "\n",
    "\n",
    "print(\"For Adult Dataset\")\n",
    "print(\"Accuracy from implementation: {}%\".format(adult_accuracy), end=\"\\n\\n\")\n",
    "\n",
    "print(\"For BUPA Dataset\")\n",
    "print(\"Accuracy from implementation: {}%\".format(bupa_accuracy), end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
